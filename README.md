# Implementation of CAREL on Semantic HELM: A Human-Readable Memory for Reinforcement Learning

This repository presents an implementation of CAREL (Cross-modal Auxiliary REinforcement Learning) on the Semantic HELM (SHELM). CAREL is a reinforcement learning framework that incorporates the concept of cross-modality to enhance agent learning.

In this repository, we have extended and modified the original SHELM codebase to include the CAREL auxiliary loss. The integration of CAREL allows agents to explore their environment more effectively, ultimately improving their performance and sample effectiency.
